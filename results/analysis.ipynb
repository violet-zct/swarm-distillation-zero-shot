{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ed7569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis.ipynb\n",
      "anli_none_dev_r1_bigscience.T0\n",
      "anli_none_dev_r1_bigscience.T0_3B\n",
      "anli_none_dev_r2_bigscience.T0\n",
      "anli_none_dev_r2_bigscience.T0_3B\n",
      "anli_none_dev_r3_bigscience.T0\n",
      "anli_none_dev_r3_bigscience.T0_3B\n",
      "hellaswag_none_validation_bigscience.T0\n",
      "hellaswag_none_validation_bigscience.T0_3B\n",
      "super_glue_cb_validation_bigscience.T0\n",
      "super_glue_cb_validation_bigscience.T0_3B\n",
      "super_glue_copa_validation_bigscience.T0\n",
      "super_glue_copa_validation_bigscience.T0_3B\n",
      "super_glue_rte_validation_bigscience.T0\n",
      "super_glue_rte_validation_bigscience.T0_3B\n",
      "super_glue_wic_validation_bigscience.T0\n",
      "super_glue_wic_validation_bigscience.T0_3B\n",
      "super_glue_wsc.fixed_validation_bigscience.T0\n",
      "super_glue_wsc.fixed_validation_bigscience.T0_3B\n",
      "winogrande_winogrande_xl_validation_bigscience.T0\n",
      "winogrande_winogrande_xl_validation_bigscience.T0_3B\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac25ded5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset anli (/data/home/chuntinz/.cache/huggingface/datasets/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01484537124633789,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 9,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ba6787826941439b149070e00c3c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-3 style', 'MNLI crowdsource', 'always/sometimes/never', 'based on the previous passage', 'can we infer', 'claim true/false/inconclusive', 'consider always/sometimes/never', 'does it follow that', 'does this imply', 'guaranteed true', 'guaranteed/possible/impossible', 'justified in saying', 'must be true', 'should assume', 'take the following as truth']\n",
      "Guaranteed\n",
      "========\n",
      "{'uid': 'e66af435-eef1-491b-af2a-4825d54611e1', 'premise': 'Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right \"Forza Italia\" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci.', 'hypothesis': 'Franco Zeffirelli had a political career', 'label': 0, 'reason': 'Franco Zeffirelli was a senator so he had a political career. The system likely was fooled because I used words not used in the context.'}\n",
      "===========\n",
      "Assume it is true that Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right \"Forza Italia\" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. \n",
      "\n",
      "Therefore, \"Franco Zeffirelli had a political career\" is guaranteed, possible, or impossible?\n",
      "========\n",
      "Guaranteed\n",
      "\n",
      "['Guaranteed', 'Possible', 'Impossible']\n"
     ]
    }
   ],
   "source": [
    "from promptsource.templates import DatasetTemplates\n",
    "import datasets\n",
    "data = datasets.load_dataset(\"anli\")\n",
    "data = data[\"dev_r1\"]\n",
    "prompts = DatasetTemplates(\"anli\", None)\n",
    "prompt_names = prompts.all_template_names\n",
    "print(prompt_names)\n",
    "pname = 'guaranteed/possible/impossible'\n",
    "k = 1\n",
    "input, output = prompts[pname].apply(data[k])\n",
    "targets = prompts[pname].get_answer_choices_list(data[k])\n",
    "\n",
    "print(output.strip())\n",
    "print(\"========\")\n",
    "print(data[k])\n",
    "print(\"===========\")\n",
    "print(input)\n",
    "print(\"========\")\n",
    "print(output)\n",
    "print()\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e83225f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10}\n",
      "anli_none_dev_r1_bigscience.T0: max_acc = 46.5, oracle_acc = 80.2, median_acc = 44.7, min_acc = 33.3, ensemble_acc = 45.5\n",
      "{10}\n",
      "anli_none_dev_r2_bigscience.T0: max_acc = 40.8, oracle_acc = 78.9, median_acc = 39.7, min_acc = 33.5, ensemble_acc = 39.9\n",
      "{10}\n",
      "anli_none_dev_r3_bigscience.T0: max_acc = 44.25, oracle_acc = 79.58333333333333, median_acc = 42.67, min_acc = 33.92, ensemble_acc = 43.33\n",
      "set()\n",
      "hellaswag_none_validation_bigscience.T0: max_acc = 34.13, oracle_acc = 64.35968930491934, median_acc = 33.67, min_acc = 33.18, ensemble_acc = 34.8\n",
      "{10}\n",
      "super_glue_cb_validation_bigscience.T0: max_acc = 80.36, oracle_acc = 98.21428571428571, median_acc = 78.57, min_acc = 8.93, ensemble_acc = 78.57\n",
      "set()\n",
      "super_glue_copa_validation_bigscience.T0: max_acc = 96.0, oracle_acc = 99.0, median_acc = 93.0, min_acc = 82.0, ensemble_acc = 94.0\n",
      "set()\n",
      "super_glue_rte_validation_bigscience.T0: max_acc = 84.84, oracle_acc = 93.14079422382672, median_acc = 82.31, min_acc = 73.65, ensemble_acc = 84.48\n",
      "{1, 3, 5, 7}\n",
      "super_glue_wic_validation_bigscience.T0: max_acc = 58.46, oracle_acc = 89.96865203761756, median_acc = 56.66, min_acc = 51.72, ensemble_acc = 55.96\n",
      "{7}\n",
      "super_glue_wsc.fixed_validation_bigscience.T0: max_acc = 69.23, oracle_acc = 97.11538461538461, median_acc = 62.5, min_acc = 49.04, ensemble_acc = 63.46\n",
      "{2}\n",
      "winogrande_winogrande_xl_validation_bigscience.T0: max_acc = 63.77, oracle_acc = 79.55801104972376, median_acc = 60.38, min_acc = 56.27, ensemble_acc = 60.62\n",
      "{1, 2, 10, 6}\n",
      "anli_none_dev_r1_bigscience.T0_3B: max_acc = 36.0, oracle_acc = 52.4, median_acc = 33.6, min_acc = 32.4, ensemble_acc = 34.2\n",
      "{1, 2, 10, 6}\n",
      "anli_none_dev_r2_bigscience.T0_3B: max_acc = 35.1, oracle_acc = 53.2, median_acc = 33.4, min_acc = 30.4, ensemble_acc = 32.9\n",
      "{1, 2, 4, 6, 8, 10}\n",
      "anli_none_dev_r3_bigscience.T0_3B: max_acc = 34.08, oracle_acc = 50.0, median_acc = 33.33, min_acc = 32.58, ensemble_acc = 33.25\n",
      "set()\n",
      "hellaswag_none_validation_bigscience.T0_3B: max_acc = 28.46, oracle_acc = 60.446126269667396, median_acc = 27.32, min_acc = 25.65, ensemble_acc = 27.87\n",
      "{1, 2, 10}\n",
      "super_glue_cb_validation_bigscience.T0_3B: max_acc = 64.29, oracle_acc = 85.71428571428571, median_acc = 50.0, min_acc = 8.93, ensemble_acc = 53.57\n",
      "set()\n",
      "super_glue_copa_validation_bigscience.T0_3B: max_acc = 84.0, oracle_acc = 94.0, median_acc = 79.0, min_acc = 61.0, ensemble_acc = 81.0\n",
      "{1, 3, 4, 5, 7}\n",
      "super_glue_rte_validation_bigscience.T0_3B: max_acc = 70.04, oracle_acc = 77.25631768953069, median_acc = 64.08, min_acc = 59.57, ensemble_acc = 66.79\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "super_glue_wic_validation_bigscience.T0_3B: max_acc = 52.51, oracle_acc = 52.507836990595614, median_acc = 50.39, min_acc = 49.69, ensemble_acc = 50.16\n",
      "{3, 4, 5, 7, 8, 9}\n",
      "super_glue_wsc.fixed_validation_bigscience.T0_3B: max_acc = 69.23, oracle_acc = 85.57692307692308, median_acc = 64.9, min_acc = 60.58, ensemble_acc = 66.35\n",
      "set()\n",
      "winogrande_winogrande_xl_validation_bigscience.T0_3B: max_acc = 52.49, oracle_acc = 79.08445146014206, median_acc = 50.51, min_acc = 49.25, ensemble_acc = 51.07\n",
      "correlation = (0.8691869245498127, 6.852489746191231e-34)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import scipy.stats\n",
    "\n",
    "def read_file(fname):\n",
    "    lidx = -1\n",
    "    eidx = -1\n",
    "    all_preds_per_example = []\n",
    "    all_golds = []\n",
    "    all_preds_per_prompt = []\n",
    "    with open(fname) as fin:\n",
    "        for line in fin:\n",
    "            lidx += 1\n",
    "            if lidx == 0:\n",
    "                fields = line.strip().split(',')\n",
    "                num_prompts, num_examples = int(fields[0].split(\"=\")[1].strip()), int(fields[1].split(\"=\")[1].strip())\n",
    "                all_preds_per_prompt = [[] for _ in range(num_prompts)]\n",
    "            elif lidx == 1:\n",
    "                fields = line.strip().split(',')\n",
    "                max_acc, median_acc, min_acc, ensemble_acc = float(fields[0].split(\"=\")[1].strip()), float(fields[1].split(\"=\")[1].strip()), float(fields[3].split(\"=\")[1].strip()), float(fields[-1].split(\"=\")[1].strip())\n",
    "            elif lidx == 2:\n",
    "                prompts_accuracy = list(map(float, line.strip().split(':')[1].strip().split()))\n",
    "            elif lidx == 3:\n",
    "                pass\n",
    "            elif line.startswith(\"=====\"):\n",
    "                eidx += 1\n",
    "            elif line.startswith(\"eid\"):\n",
    "                fields = line.strip().split(',')\n",
    "                gold = int(fields[1].split(\"=\")[1])\n",
    "                preds = list(map(int, fields[-1].strip().split()))\n",
    "                all_preds_per_example.append(preds)\n",
    "                all_golds.append(gold)\n",
    "                for pid, pp in enumerate(preds):\n",
    "                    all_preds_per_prompt[pid].append(pp)\n",
    "            else:\n",
    "                # read pred probs\n",
    "                pass\n",
    "    return num_prompts, num_examples, all_preds_per_example, all_preds_per_prompt, all_golds, prompts_accuracy, max_acc, median_acc, min_acc, ensemble_acc\n",
    "\n",
    "test_file_names = ['anli_none_dev_r1_bigscience.T0', 'anli_none_dev_r2_bigscience.T0', 'anli_none_dev_r3_bigscience.T0', \n",
    "                  'hellaswag_none_validation_bigscience.T0', 'super_glue_cb_validation_bigscience.T0',\n",
    "                  'super_glue_copa_validation_bigscience.T0', 'super_glue_rte_validation_bigscience.T0',\n",
    "                  'super_glue_wic_validation_bigscience.T0', 'super_glue_wsc.fixed_validation_bigscience.T0', 'winogrande_winogrande_xl_validation_bigscience.T0']\n",
    "\n",
    "t0_11b = {}\n",
    "for fname in test_file_names:\n",
    "    num_prompts, num_examples, all_preds_per_example, all_preds_per_prompt, all_golds, prompts_accuracy, max_acc, median_acc, min_acc, ensemble_acc = read_file(fname)\n",
    "    t0_11b[fname] = {\"nprompts\": num_prompts, 'nexamples': num_examples, 'all_preds_per_example': all_preds_per_example, 'all_preds_per_prompt': all_preds_per_prompt, \"all_golds\": all_golds, \n",
    "                    \"prompts_accuracy\": prompts_accuracy, 'max_acc': max_acc, 'median_acc': median_acc, 'min_acc': min_acc, 'ensemble_acc': ensemble_acc}\n",
    "    \n",
    "t0_3b = {}\n",
    "for fname in test_file_names:\n",
    "    num_prompts, num_examples, all_preds_per_example, all_preds_per_prompt, all_golds, prompts_accuracy, max_acc, median_acc, min_acc, ensemble_acc = read_file(fname+\"_3B\")\n",
    "    t0_3b[fname] = {\"nprompts\": num_prompts, 'nexamples': num_examples, 'all_preds_per_example': all_preds_per_example, 'all_preds_per_prompt': all_preds_per_prompt, \"all_golds\": all_golds, \n",
    "                    \"prompts_accuracy\": prompts_accuracy, 'max_acc': max_acc, 'median_acc': median_acc, 'min_acc': min_acc, 'ensemble_acc': ensemble_acc}\n",
    "    \n",
    "\n",
    "def cal_task_prompt_oracle_acc(task_dict, suffix=\"\"):\n",
    "    for fname in test_file_names:\n",
    "        results = task_dict[fname]\n",
    "        degenerate_prompts = set()\n",
    "        for pid, preds in enumerate(task_dict[fname]['all_preds_per_prompt']):\n",
    "            if len(set(preds)) == 1:\n",
    "                degenerate_prompts.add(pid)\n",
    "            else:\n",
    "                count = Counter(preds)\n",
    "                if max(np.array(list(count.values()))*1.0 / sum(count.values())) > 0.8:\n",
    "                    degenerate_prompts.add(pid)\n",
    "            \n",
    "        all_preds_per_example = task_dict[fname]['all_preds_per_example']\n",
    "        all_golds = task_dict[fname]['all_golds']\n",
    "        print(degenerate_prompts)\n",
    "        count = 0\n",
    "        for pred_per_example, gold in zip(all_preds_per_example, all_golds):\n",
    "            pred_per_example = [pred_per_example[i] for i in range(len(all_preds_per_example[0])) if i not in degenerate_prompts]\n",
    "            count += 1 if gold in pred_per_example else 0\n",
    "#             if pred_per_example.count(gold) >= 2:\n",
    "#                 count += 1\n",
    "        oracle_acc = count * 100. / len(all_golds)\n",
    "        max_acc, median_acc, min_acc, ensemble_acc = task_dict[fname]['max_acc'], task_dict[fname]['median_acc'], task_dict[fname]['min_acc'], task_dict[fname]['ensemble_acc'], \n",
    "        print(\"{}{}: max_acc = {}, oracle_acc = {}, median_acc = {}, min_acc = {}, ensemble_acc = {}\".format(fname, suffix, max_acc, oracle_acc, median_acc, min_acc, ensemble_acc))\n",
    "        \n",
    "cal_task_prompt_oracle_acc(t0_11b)\n",
    "cal_task_prompt_oracle_acc(t0_3b, \"_3B\")\n",
    "\n",
    "def cal_correlation():\n",
    "    t11b_accs, t3b_accs = [], []\n",
    "    for fname in test_file_names:\n",
    "        t11b_accs.extend(t0_11b[fname][\"prompts_accuracy\"])\n",
    "        t3b_accs.extend(t0_3b[fname][\"prompts_accuracy\"])\n",
    "    corr = scipy.stats.pearsonr(t11b_accs, t3b_accs)\n",
    "    print(\"correlation = {}\".format(corr))\n",
    "\n",
    "cal_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc236397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================================================================================================================================================================================================================================================\n",
      "app_reviews None train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset app_reviews (../pretrain_models/huggingface/app_reviews/default/0.0.0/20335b51b604b9bc04b7be253cd8445caa9ba93f15f39a4b0492b9e9102853de)\n",
      "100%|██████████| 1/1 [00:00<00:00, 439.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train'])\n",
      "288065\n",
      "total prompts = 4, original prompts = 0\n",
      "dict_keys(['package_name', 'review', 'date', 'star'])\n",
      "{'package_name': 'com.mantz_it.rfanalyzer', 'review': \"Great app! The new version now works on my Bravia Android TV which is great as it's right by my rooftop aerial cable. The scan feature would be useful...any ETA on when this will be available? Also the option to import a list of bookmarks e.g. from a simple properties file would be useful.\", 'date': 'October 12 2016', 'star': 4}\n",
      "\n",
      "non original =========== categorize_rating_using_review.['Accuracy', 'Spearman Correlation'] ===========\n",
      "Given this review: \"{{review}}\"\n",
      "Would you recommend this app to a friend? {{answer_choices[0]}}, {{answer_choices[1]}}, {{answer_choices[2]}}, {{answer_choices[3]}}, or {{answer_choices[4]}}?\n",
      "|||\n",
      "{{answer_choices[star-1]}}\n",
      "++++++\n",
      "5 ['Not at all', 'No', 'Maybe', 'Yes', 'Definitely']\n",
      "++++++\n",
      "['Given this review: \"Great app! The new version now works on my Bravia Android TV which is great as it\\'s right by my rooftop aerial cable. The scan feature would be useful...any ETA on when this will be available? Also the option to import a list of bookmarks e.g. from a simple properties file would be useful.\"\\nWould you recommend this app to a friend? Not at all, No, Maybe, Yes, or Definitely?', 'Yes']\n",
      "['Given this review: \"Works well with my Hackrf Hopefully new updates will arrive for extra functions\"\\nWould you recommend this app to a friend? Not at all, No, Maybe, Yes, or Definitely?', 'Definitely']\n",
      "\n",
      "non original =========== convert_to_rating.['Accuracy', 'Spearman Correlation'] ===========\n",
      "On a scale of 1-5 (with 1 being least favorable and 5 being most favorable), how would you rate this review? \"{{review}}\"\n",
      "|||\n",
      "{{star}}\n",
      "['On a scale of 1-5 (with 1 being least favorable and 5 being most favorable), how would you rate this review? \"Great app! The new version now works on my Bravia Android TV which is great as it\\'s right by my rooftop aerial cable. The scan feature would be useful...any ETA on when this will be available? Also the option to import a list of bookmarks e.g. from a simple properties file would be useful.\"', '4']\n",
      "['On a scale of 1-5 (with 1 being least favorable and 5 being most favorable), how would you rate this review? \"Works well with my Hackrf Hopefully new updates will arrive for extra functions\"', '5']\n",
      "\n",
      "non original =========== convert_to_star_rating.['Accuracy', 'Spearman Correlation'] ===========\n",
      "What would be the ★-rating of this review (★ being the lowest and ★★★★★ being the highest)? \"{{review}}\"\n",
      "|||\n",
      "{{answer_choices[star-1]}}\n",
      "++++++\n",
      "5 ['★', '★★', '★★★', '★★★★', '★★★★★']\n",
      "++++++\n",
      "['What would be the ★-rating of this review (★ being the lowest and ★★★★★ being the highest)? \"Great app! The new version now works on my Bravia Android TV which is great as it\\'s right by my rooftop aerial cable. The scan feature would be useful...any ETA on when this will be available? Also the option to import a list of bookmarks e.g. from a simple properties file would be useful.\"', '★★★★']\n",
      "['What would be the ★-rating of this review (★ being the lowest and ★★★★★ being the highest)? \"Works well with my Hackrf Hopefully new updates will arrive for extra functions\"', '★★★★★']\n",
      "\n",
      "non original =========== generate_review.['Accuracy', 'Spearman Correlation'] ===========\n",
      "Generate a {{star}}-star review (1 being lowest and 5 being highest) about an app with package {{package_name}}.\n",
      "|||\n",
      "{{review}}\n",
      "['Generate a 4-star review (1 being lowest and 5 being highest) about an app with package com.mantz_it.rfanalyzer.', \"Great app! The new version now works on my Bravia Android TV which is great as it's right by my rooftop aerial cable. The scan feature would be useful...any ETA on when this will be available? Also the option to import a list of bookmarks e.g. from a simple properties file would be useful.\"]\n",
      "['Generate a 5-star review (1 being lowest and 5 being highest) about an app with package com.mantz_it.rfanalyzer.', 'Works well with my Hackrf Hopefully new updates will arrive for extra functions']\n",
      "datasets with more than 2 original prompts: 0\n",
      "datasets with only non-original prompts: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "! export TRANSFORMERS_CACHE=../pretrain_models/huggingface\n",
    "! export HF_DATASETS_CACHE=../pretrain_models/huggingface\n",
    "! export HF_METRICS_CACHE=../pretrain_models/huggingface\n",
    "! cache_dir=../pretrain_models/huggingface\n",
    "\n",
    "# T0 train set\n",
    "\n",
    "from os import read\n",
    "from promptsource.templates import DatasetTemplates\n",
    "import datasets\n",
    "cache_dir='../pretrain_models/huggingface'\n",
    "\n",
    "all_datasets = [('glue', 'mrpc', 'validation'), ('glue', 'qqp', 'validation'), ('paws', 'labeled_final', 'validation'), ('ai2_arc', 'ARC-Challenge', 'validation'), ('ai2_arc', 'ARC-Easy', 'validation'), ('kilt_tasks', 'hotpotqa', 'validation'), ('trivia_qa', 'unfiltered', 'validation'), ('web_questions', None, 'test'), ('wiki_qa', None, 'validation'), ('adversarial_qa', 'dbidaf', 'validation'), ('adversarial_qa', 'dbert', 'validation'), ('adversarial_qa', 'droberta', 'validation'), ('duorc', 'SelfRC', 'validation'), ('duorc', 'ParaphraseRC', 'validation'), ('ropes', None, 'validation'), ('squad_v2', None, 'validation'), ('super_glue', 'record', 'validation'), ('quoref', None, 'validation'), ('tydiqa', 'primary_task', 'validation'), ('cos_e', 'v1.11', 'validation'), ('cosmos_qa', None, 'validation'), ('dream', None, 'validation'), ('openbookqa', 'main', 'validation'), ('qasc', None, 'validation'), ('quail', None, 'validation'), ('quarel', None, 'validation'), ('quartz', None, 'validation'), ('race', 'high', 'validation'), ('race', 'middle', 'validation'), ('sciq', None, 'validation'), ('social_i_qa', None, 'validation'), ('super_glue', 'boolq', 'validation'), ('super_glue', 'multirc', 'validation'), ('wiki_hop', 'original', 'validation'), ('wiqa', None, 'validation'), ('piqa', None, 'validation'), ('amazon_polarity', None, 'test'), ('app_reviews', None, 'train'), ('imdb', None, 'test'), ('rotten_tomatoes', None, 'validation'), ('yelp_review_full', None, 'test'), ('common_gen', None, 'validation'), ('wiki_bio', None, 'val'), ('cnn_dailymail', '3.0.0', 'validation'), ('gigaword', None, 'validation'), ('multi_news', None, 'validation'), ('xsum', None, 'validation'), ('samsum', None, 'validation'), ('ag_news', None, 'test'), ('dbpedia_14', None, 'test'), ('trec', None, 'test')]\n",
    "\n",
    "datasets_with_more_than_2_original_prompts = 0\n",
    "datasets_with_only_nonoriginal_prompts = 0\n",
    "\n",
    "def read_prompts(dataset, subset, split):\n",
    "    global datasets_with_more_than_2_original_prompts\n",
    "    global datasets_with_only_nonoriginal_prompts\n",
    "    print()\n",
    "    print(\"===\"*100)\n",
    "    print(dataset, subset, split)\n",
    "    data = datasets.load_dataset(dataset, subset, cache_dir=cache_dir)\n",
    "    print(data.keys())\n",
    "    data = data[split]\n",
    "    print(len(data))\n",
    "    prompts = DatasetTemplates(dataset, subset)\n",
    "    prompt_names = prompts.all_template_names\n",
    "    original_prompts =[n for n in prompt_names if prompts[n].metadata.original_task]\n",
    "    non_original_prompts = [n for n in prompt_names if not prompts[n].metadata.original_task]\n",
    "    print(\"total prompts = {}, original prompts = {}\".format(len(prompt_names), len(original_prompts)))\n",
    "\n",
    "    # choices = prompts[prompt_names[0]].get_answer_choices_list(data[0])\n",
    "    # print(data[0].keys())\n",
    "    # if choices is not None:\n",
    "    #     print(\"number of choices = {}, {}\".format(len(choices), choices))\n",
    "    # else:\n",
    "    #     print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>> no choices >>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "    print(data[0].keys())\n",
    "    print(data[0])\n",
    "    if len(original_prompts) > 0:\n",
    "        print(prompts[original_prompts[0]].apply(data[0]))\n",
    "        for pp in original_prompts:\n",
    "            print('\\noriginal =========== {}: {} ==========='.format(pp, prompts[pp].metadata.metrics))\n",
    "            print(prompts[pp].jinja)\n",
    "            choices = prompts[pp].get_answer_choices_list(data[0])\n",
    "            if choices is not None:\n",
    "                print(\"++++++\")\n",
    "                print(choices)\n",
    "                print(\"++++++\")\n",
    "            print(prompts[pp].apply(data[0]))\n",
    "            print(prompts[pp].apply(data[4]))\n",
    "    if len(non_original_prompts) > 0:\n",
    "        for pp in non_original_prompts:\n",
    "            print('\\nnon original =========== {}.{} ==========='.format(pp, prompts[pp].metadata.metrics))\n",
    "            print(prompts[pp].jinja)\n",
    "            choices = prompts[pp].get_answer_choices_list(data[0])\n",
    "            if choices is not None:\n",
    "                print(\"++++++\")\n",
    "                print(len(choices), choices)\n",
    "                print(\"++++++\")\n",
    "            print(prompts[pp].apply(data[0]))\n",
    "            print(prompts[pp].apply(data[4]))\n",
    "    \n",
    "    if len(original_prompts) >= 3:\n",
    "        datasets_with_more_than_2_original_prompts += 1\n",
    "    if len(original_prompts) == 0:\n",
    "        datasets_with_only_nonoriginal_prompts += 1\n",
    "\n",
    "read_prompts(\"app_reviews\", None, \"train\")\n",
    "# a = 50\n",
    "# b = 51\n",
    "# for dataset, subset, split in all_datasets[a:b]:\n",
    "#     print(dataset, subset, split)\n",
    "#     read_prompts(dataset, subset, split)\n",
    "\n",
    "\n",
    "print(\"datasets with more than 2 original prompts: {}\".format(datasets_with_more_than_2_original_prompts))\n",
    "print(\"datasets with only non-original prompts: {}\".format(datasets_with_only_nonoriginal_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09b2fac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 11:44:03.906098: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-23 11:44:04.016803: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-23 11:44:04.022006: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /private/home/chuntinz/work/tools/lib/::/public/slurm/20.11.8/lib:/public/slurm/20.11.8/lib\n",
      "2022-09-23 11:44:04.022019: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-23 11:44:04.046951: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-23 11:44:05.312429: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /private/home/chuntinz/work/tools/lib/::/public/slurm/20.11.8/lib:/public/slurm/20.11.8/lib\n",
      "2022-09-23 11:44:05.312510: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /private/home/chuntinz/work/tools/lib/::/public/slurm/20.11.8/lib:/public/slurm/20.11.8/lib\n",
      "2022-09-23 11:44:05.312518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/private/home/chuntinz/checkpoint/research/swarm-distillation-zero-shot/results/analysis.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfair/private/home/chuntinz/checkpoint/research/swarm-distillation-zero-shot/results/analysis.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39m cache_dir=../pretrain_models/huggingface\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfair/private/home/chuntinz/checkpoint/research/swarm-distillation-zero-shot/results/analysis.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# read_prompts(\"hotpot_qa\", \"fullwiki\", \"validation\")\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfair/private/home/chuntinz/checkpoint/research/swarm-distillation-zero-shot/results/analysis.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m data \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mload_dataset(\u001b[39m'\u001b[39;49m\u001b[39mbigscience/P3\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtrivia_qa_unfiltered_first_person_context\u001b[39;49m\u001b[39m\"\u001b[39;49m, cache_dir\u001b[39m=\u001b[39;49mcache_dir)[\u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfair/private/home/chuntinz/checkpoint/research/swarm-distillation-zero-shot/results/analysis.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(data[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/datasets/load.py:1723\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, **config_kwargs)\u001b[0m\n\u001b[1;32m   1720\u001b[0m ignore_verifications \u001b[39m=\u001b[39m ignore_verifications \u001b[39mor\u001b[39;00m save_infos\n\u001b[1;32m   1722\u001b[0m \u001b[39m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 1723\u001b[0m builder_instance \u001b[39m=\u001b[39m load_dataset_builder(\n\u001b[1;32m   1724\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m   1725\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1726\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1727\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1728\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1729\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   1730\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1731\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1732\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1733\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1734\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig_kwargs,\n\u001b[1;32m   1735\u001b[0m )\n\u001b[1;32m   1737\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/datasets/load.py:1500\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, use_auth_token, **config_kwargs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     download_config \u001b[39m=\u001b[39m download_config\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m download_config \u001b[39melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1499\u001b[0m     download_config\u001b[39m.\u001b[39muse_auth_token \u001b[39m=\u001b[39m use_auth_token\n\u001b[0;32m-> 1500\u001b[0m dataset_module \u001b[39m=\u001b[39m dataset_module_factory(\n\u001b[1;32m   1501\u001b[0m     path,\n\u001b[1;32m   1502\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1503\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1504\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1505\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1506\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1507\u001b[0m )\n\u001b[1;32m   1509\u001b[0m \u001b[39m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m builder_cls \u001b[39m=\u001b[39m import_main_class(dataset_module\u001b[39m.\u001b[39mmodule_path)\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/datasets/load.py:1220\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m   1219\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39min\u001b[39;00m [sibling\u001b[39m.\u001b[39mrfilename \u001b[39mfor\u001b[39;00m sibling \u001b[39min\u001b[39;00m dataset_info\u001b[39m.\u001b[39msiblings]:\n\u001b[0;32m-> 1220\u001b[0m     \u001b[39mreturn\u001b[39;00m HubDatasetModuleFactoryWithScript(\n\u001b[1;32m   1221\u001b[0m         path,\n\u001b[1;32m   1222\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1223\u001b[0m         download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1224\u001b[0m         download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1225\u001b[0m         dynamic_modules_path\u001b[39m=\u001b[39;49mdynamic_modules_path,\n\u001b[1;32m   1226\u001b[0m     )\u001b[39m.\u001b[39;49mget_module()\n\u001b[1;32m   1227\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[39mreturn\u001b[39;00m HubDatasetModuleFactoryWithoutScript(\n\u001b[1;32m   1229\u001b[0m         path,\n\u001b[1;32m   1230\u001b[0m         revision\u001b[39m=\u001b[39mrevision,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1234\u001b[0m         download_mode\u001b[39m=\u001b[39mdownload_mode,\n\u001b[1;32m   1235\u001b[0m     )\u001b[39m.\u001b[39mget_module()\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/datasets/load.py:931\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithScript.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m dataset_infos_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload_dataset_infos_file()\n\u001b[1;32m    930\u001b[0m imports \u001b[39m=\u001b[39m get_imports(local_path)\n\u001b[0;32m--> 931\u001b[0m local_imports \u001b[39m=\u001b[39m _download_additional_modules(\n\u001b[1;32m    932\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    933\u001b[0m     base_path\u001b[39m=\u001b[39;49mhf_hub_url(repo_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m, revision\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrevision),\n\u001b[1;32m    934\u001b[0m     imports\u001b[39m=\u001b[39;49mimports,\n\u001b[1;32m    935\u001b[0m     download_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_config,\n\u001b[1;32m    936\u001b[0m )\n\u001b[1;32m    937\u001b[0m additional_files \u001b[39m=\u001b[39m [(config\u001b[39m.\u001b[39mDATASETDICT_INFOS_FILENAME, dataset_infos_path)] \u001b[39mif\u001b[39;00m dataset_infos_path \u001b[39melse\u001b[39;00m []\n\u001b[1;32m    938\u001b[0m \u001b[39m# copy the script and the files in an importable directory\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/datasets/load.py:208\u001b[0m, in \u001b[0;36m_download_additional_modules\u001b[0;34m(name, base_path, imports, download_config)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mfor\u001b[39;00m library_import_name, library_import_path \u001b[39min\u001b[39;00m library_imports:\n\u001b[1;32m    207\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m         lib \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(library_import_name)  \u001b[39m# noqa F841\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         \u001b[39mif\u001b[39;00m library_import_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m needs_to_be_installed \u001b[39mor\u001b[39;00m library_import_path \u001b[39m!=\u001b[39m library_import_name:\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:975\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:671\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:843\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:219\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/tensorflow/__init__.py:469\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_current_module, \u001b[39m\"\u001b[39m\u001b[39mkeras\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    468\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 469\u001b[0m     _keras\u001b[39m.\u001b[39;49m_load()\n\u001b[1;32m    470\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n\u001b[1;32m     44\u001b[0m \u001b[39m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:961\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:219\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:961\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:219\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:961\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:219\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:975\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:671\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:843\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:219\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/keras/__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/keras/models/__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/keras/engine/functional.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m input_spec\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m node \u001b[39mas\u001b[39;00m node_module\n\u001b[0;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m training \u001b[39mas\u001b[39;00m training_lib\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m training_utils\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m json_utils\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/keras/engine/training.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer_utils\n\u001b[0;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m compile_utils\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m data_adapter\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m input_layer \u001b[39mas\u001b[39;00m input_layer_module\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/keras/engine/compile_utils.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m losses \u001b[39mas\u001b[39;00m losses_mod\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics \u001b[39mas\u001b[39;00m metrics_mod\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m \u001b[39mimport\u001b[39;00m saving_lib\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m generic_utils\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/keras/metrics/__init__.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_metric\u001b[39;00m \u001b[39mimport\u001b[39;00m clone_metrics\n\u001b[1;32m     31\u001b[0m \u001b[39m# Metric functions\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m# Individual metric classes\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m AUC\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m Accuracy\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m BinaryAccuracy\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/keras/metrics/metrics.py:28\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m utils \u001b[39mas\u001b[39;00m dtensor_utils\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/keras/activations.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivation\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mactivation_layers\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m generic_utils\n",
      "File \u001b[0;32m~/.conda/envs/t0/lib/python3.8/site-packages/keras/layers/__init__.py:130\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnormalization\u001b[39;00m \u001b[39mimport\u001b[39;00m Normalization\n\u001b[1;32m    129\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstring_lookup\u001b[39;00m \u001b[39mimport\u001b[39;00m StringLookup\n\u001b[0;32m--> 130\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext_vectorization\u001b[39;00m \u001b[39mimport\u001b[39;00m TextVectorization\n\u001b[1;32m    131\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregularization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivity_regularization\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m     ActivityRegularization,\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    134\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregularization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malpha_dropout\u001b[39;00m \u001b[39mimport\u001b[39;00m AlphaDropout\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:975\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:671\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:839\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:934\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "! export TRANSFORMERS_CACHE=../pretrain_models/huggingface\n",
    "! export HF_DATASETS_CACHE=../pretrain_models/huggingface\n",
    "! export HF_METRICS_CACHE=../pretrain_models/huggingface\n",
    "! cache_dir=../pretrain_models/huggingface\n",
    "       \n",
    "# read_prompts(\"hotpot_qa\", \"fullwiki\", \"validation\")\n",
    "\n",
    "data = datasets.load_dataset('bigscience/P3', \"trivia_qa_unfiltered_first_person_context\", cache_dir=cache_dir)[\"validation\"]\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47acfb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = ['adversarial_qa_dbert_answer_the_following_q', 'adversarial_qa_dbert_based_on', 'adversarial_qa_dbert_generate_question', 'adversarial_qa_dbert_question_context_answer', 'adversarial_qa_dbert_tell_what_it_is', 'adversarial_qa_dbidaf_answer_the_following_q', 'adversarial_qa_dbidaf_based_on', 'adversarial_qa_dbidaf_generate_question', 'adversarial_qa_dbidaf_question_context_answer', 'adversarial_qa_dbidaf_tell_what_it_is', 'adversarial_qa_droberta_answer_the_following_q', 'adversarial_qa_droberta_based_on', 'adversarial_qa_droberta_generate_question', 'adversarial_qa_droberta_question_context_answer', 'adversarial_qa_droberta_tell_what_it_is', 'ag_news_classify', 'ag_news_classify_question_first', 'ag_news_classify_with_choices', 'ag_news_classify_with_choices_question_first', 'ag_news_recommend', 'ag_news_which_section', 'ag_news_which_section_choices', 'ai2_arc_ARC_Challenge_heres_a_problem', 'ai2_arc_ARC_Challenge_i_am_hesitating', 'ai2_arc_ARC_Challenge_multiple_choice', 'ai2_arc_ARC_Challenge_pick_false_options', 'ai2_arc_ARC_Challenge_pick_the_most_correct_option', 'ai2_arc_ARC_Challenge_qa_options', 'ai2_arc_ARC_Easy_heres_a_problem', 'ai2_arc_ARC_Easy_i_am_hesitating', 'ai2_arc_ARC_Easy_multiple_choice', 'ai2_arc_ARC_Easy_pick_false_options', 'ai2_arc_ARC_Easy_pick_the_most_correct_option', 'ai2_arc_ARC_Easy_qa_options', 'amazon_polarity_Is_this_product_review_positive', 'amazon_polarity_Is_this_review', 'amazon_polarity_Is_this_review_negative', 'amazon_polarity_User_recommend_this_product', 'amazon_polarity_convey_negative_or_positive_sentiment', 'amazon_polarity_flattering_or_not', 'amazon_polarity_negative_or_positive_tone', 'amazon_polarity_user_satisfied', 'amazon_polarity_would_you_buy', 'anli_GPT_3_style_r1', 'anli_GPT_3_style_r1_score_eval', 'anli_GPT_3_style_r2', 'anli_GPT_3_style_r2_score_eval', 'anli_GPT_3_style_r3', 'anli_GPT_3_style_r3_score_eval', 'anli_MNLI_crowdsource_r1', 'anli_MNLI_crowdsource_r1_score_eval', 'anli_MNLI_crowdsource_r2', 'anli_MNLI_crowdsource_r2_score_eval', 'anli_MNLI_crowdsource_r3', 'anli_MNLI_crowdsource_r3_score_eval', 'anli_always_sometimes_never_r1', 'anli_always_sometimes_never_r1_score_eval', 'anli_always_sometimes_never_r2', 'anli_always_sometimes_never_r2_score_eval', 'anli_always_sometimes_never_r3', 'anli_always_sometimes_never_r3_score_eval', 'anli_based_on_the_previous_passage_r1', 'anli_based_on_the_previous_passage_r1_score_eval', 'anli_based_on_the_previous_passage_r2', 'anli_based_on_the_previous_passage_r2_score_eval', 'anli_based_on_the_previous_passage_r3', 'anli_based_on_the_previous_passage_r3_score_eval', 'anli_can_we_infer_r1', 'anli_can_we_infer_r1_score_eval', 'anli_can_we_infer_r2', 'anli_can_we_infer_r2_score_eval', 'anli_can_we_infer_r3', 'anli_can_we_infer_r3_score_eval', 'anli_claim_true_false_inconclusive_r1', 'anli_claim_true_false_inconclusive_r1_score_eval', 'anli_claim_true_false_inconclusive_r2', 'anli_claim_true_false_inconclusive_r2_score_eval', 'anli_claim_true_false_inconclusive_r3', 'anli_claim_true_false_inconclusive_r3_score_eval', 'anli_consider_always_sometimes_never_r1', 'anli_consider_always_sometimes_never_r1_score_eval', 'anli_consider_always_sometimes_never_r2', 'anli_consider_always_sometimes_never_r2_score_eval', 'anli_consider_always_sometimes_never_r3', 'anli_consider_always_sometimes_never_r3_score_eval', 'anli_does_it_follow_that_r1', 'anli_does_it_follow_that_r1_score_eval', 'anli_does_it_follow_that_r2', 'anli_does_it_follow_that_r2_score_eval', 'anli_does_it_follow_that_r3', 'anli_does_it_follow_that_r3_score_eval', 'anli_does_this_imply_r1', 'anli_does_this_imply_r1_score_eval', 'anli_does_this_imply_r2', 'anli_does_this_imply_r2_score_eval', 'anli_does_this_imply_r3', 'anli_does_this_imply_r3_score_eval', 'anli_guaranteed_possible_impossible_r1', 'anli_guaranteed_possible_impossible_r1_score_eval', 'anli_guaranteed_possible_impossible_r2', 'anli_guaranteed_possible_impossible_r2_score_eval', 'anli_guaranteed_possible_impossible_r3', 'anli_guaranteed_possible_impossible_r3_score_eval', 'anli_guaranteed_true_r1', 'anli_guaranteed_true_r1_score_eval', 'anli_guaranteed_true_r2', 'anli_guaranteed_true_r2_score_eval', 'anli_guaranteed_true_r3', 'anli_guaranteed_true_r3_score_eval', 'anli_justified_in_saying_r1', 'anli_justified_in_saying_r1_score_eval', 'anli_justified_in_saying_r2', 'anli_justified_in_saying_r2_score_eval', 'anli_justified_in_saying_r3', 'anli_justified_in_saying_r3_score_eval', 'anli_must_be_true_r1', 'anli_must_be_true_r1_score_eval', 'anli_must_be_true_r2', 'anli_must_be_true_r2_score_eval', 'anli_must_be_true_r3', 'anli_must_be_true_r3_score_eval', 'anli_should_assume_r1', 'anli_should_assume_r1_score_eval', 'anli_should_assume_r2', 'anli_should_assume_r2_score_eval', 'anli_should_assume_r3', 'anli_should_assume_r3_score_eval', 'anli_take_the_following_as_truth_r1', 'anli_take_the_following_as_truth_r1_score_eval', 'anli_take_the_following_as_truth_r2', 'anli_take_the_following_as_truth_r2_score_eval', 'anli_take_the_following_as_truth_r3', 'anli_take_the_following_as_truth_r3_score_eval', 'app_reviews_categorize_rating_using_review', 'app_reviews_convert_to_rating', 'app_reviews_convert_to_star_rating', 'app_reviews_generate_review', 'cnn_dailymail_3.0.0_2_or_3_sentences', 'cnn_dailymail_3.0.0_generate_story', 'cnn_dailymail_3.0.0_news_card_view', 'cnn_dailymail_3.0.0_news_stock', 'cnn_dailymail_3.0.0_news_summary', 'cnn_dailymail_3.0.0_spice_up_story', 'cnn_dailymail_3.0.0_sum_in_brief', 'cnn_dailymail_3.0.0_tldr_summary', 'cnn_dailymail_3.0.0_write_an_outline', 'common_gen_Example_prompt', 'common_gen_Given_concepts_type_1', 'common_gen_Given_concepts_type_2', 'common_gen_Put_together', 'common_gen_choice_in_concept_centric_sentence_generation', 'common_gen_random_task_template_prompt', 'common_gen_sentence_to_concepts', 'common_gen_topic_to_sentence', 'common_gen_topics_from_the_sentence', 'cos_e_v1.11_aligned_with_common_sense', 'cos_e_v1.11_description_question_option_id', 'cos_e_v1.11_description_question_option_text', 'cos_e_v1.11_explain_why_human', 'cos_e_v1.11_generate_explanation_given_text', 'cos_e_v1.11_i_think', 'cos_e_v1.11_question_description_option_id', 'cos_e_v1.11_question_description_option_text', 'cos_e_v1.11_question_option_description_id', 'cos_e_v1.11_question_option_description_text', 'cos_e_v1.11_rationale', 'cosmos_qa_context_answer_to_question', 'cosmos_qa_context_description_question_answer_id', 'cosmos_qa_context_description_question_answer_text', 'cosmos_qa_context_description_question_text', 'cosmos_qa_context_question_description_answer_id', 'cosmos_qa_context_question_description_answer_text', 'cosmos_qa_context_question_description_text', 'cosmos_qa_description_context_question_answer_id', 'cosmos_qa_description_context_question_answer_text', 'cosmos_qa_description_context_question_text', 'cosmos_qa_no_prompt_id', 'cosmos_qa_no_prompt_text', 'cosmos_qa_only_question_answer', 'dbpedia_14_given_a_choice_of_categories_', 'dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to', 'dbpedia_14_given_list_what_category_does_the_paragraph_belong_to', 'dbpedia_14_pick_one_category_for_the_following_text', 'dream_answer_to_dialogue', 'dream_baseline', 'dream_generate_first_utterance', 'dream_generate_last_utterance', 'dream_read_the_following_conversation_and_answer_the_question', 'duorc_ParaphraseRC_answer_question', 'duorc_ParaphraseRC_build_story_around_qa', 'duorc_ParaphraseRC_decide_worth_it', 'duorc_ParaphraseRC_extract_answer', 'duorc_ParaphraseRC_generate_question', 'duorc_ParaphraseRC_generate_question_by_answer', 'duorc_ParaphraseRC_movie_director', 'duorc_ParaphraseRC_question_answering', 'duorc_ParaphraseRC_title_generation', 'duorc_SelfRC_answer_question', 'duorc_SelfRC_build_story_around_qa', 'duorc_SelfRC_decide_worth_it', 'duorc_SelfRC_extract_answer', 'duorc_SelfRC_generate_question', 'duorc_SelfRC_generate_question_by_answer', 'duorc_SelfRC_movie_director', 'duorc_SelfRC_question_answering', 'duorc_SelfRC_title_generation', 'gigaword_TLDR', 'gigaword_first_sentence_title', 'gigaword_generate_summary_for_this', 'gigaword_in_a_nutshell', 'gigaword_make_a_title', 'gigaword_reverse_writing', 'gigaword_write_a_title_for_this_sentence', 'gigaword_write_an_article', 'gigaword_write_its_sentence', 'glue_mrpc_equivalent', 'glue_mrpc_generate_paraphrase', 'glue_mrpc_generate_sentence', 'glue_mrpc_paraphrase', 'glue_mrpc_replace', 'glue_mrpc_same_thing', 'glue_mrpc_want_to_know', 'glue_qqp_answer', 'glue_qqp_duplicate', 'glue_qqp_duplicate_or_not', 'glue_qqp_meaning', 'glue_qqp_quora', 'glue_qqp_same_thing', 'hellaswag_Appropriate_continuation_Yes_or_No', 'hellaswag_Open_ended_completion', 'hellaswag_Open_ended_start', 'hellaswag_Predict_ending_with_hint', 'hellaswag_Predict_ending_with_hint_score_eval', 'hellaswag_Randomized_prompts_template', 'hellaswag_Randomized_prompts_template_score_eval', 'hellaswag_Reversed_appropriate_continuation_Yes_or_No', 'hellaswag_Topic_of_the_context', 'hellaswag_Topic_without_the_ending_answer', 'hellaswag_complete_first_then', 'hellaswag_complete_first_then_score_eval', 'hellaswag_how_ends', 'hellaswag_if_begins_how_continues', 'hellaswag_if_begins_how_continues_score_eval', 'imdb_Movie_Expressed_Sentiment', 'imdb_Movie_Expressed_Sentiment_2', 'imdb_Negation_template_for_positive_and_negative', 'imdb_Reviewer_Enjoyment', 'imdb_Reviewer_Enjoyment_Yes_No', 'imdb_Reviewer_Expressed_Sentiment', 'imdb_Reviewer_Opinion_bad_good_choices', 'imdb_Reviewer_Sentiment_Feeling', 'imdb_Sentiment_with_choices_', 'imdb_Text_Expressed_Sentiment', 'imdb_Writer_Expressed_Sentiment', 'kilt_tasks_hotpotqa_combining_facts', 'kilt_tasks_hotpotqa_complex_question', 'kilt_tasks_hotpotqa_final_exam', 'kilt_tasks_hotpotqa_formulate', 'kilt_tasks_hotpotqa_straighforward_qa', 'multi_news_distill', 'multi_news_expand_reverse_task_', 'multi_news_summarize', 'multi_news_summary_scenario', 'multi_news_synthesize', 'multi_news_what_are_the_key_points', 'openbookqa_main_choices', 'openbookqa_main_choose_an_answer_with_options', 'openbookqa_main_only_options', 'openbookqa_main_pick_answer_with_options', 'openbookqa_main_pick_using_id', 'openbookqa_main_which_correct', 'openbookqa_main_which_correct_inverse', 'paws_labeled_final_Concatenation', 'paws_labeled_final_Concatenation_no_label', 'paws_labeled_final_Meaning', 'paws_labeled_final_Meaning_no_label', 'paws_labeled_final_PAWS_ANLI_GPT3', 'paws_labeled_final_PAWS_ANLI_GPT3_no_label', 'paws_labeled_final_Rewrite', 'paws_labeled_final_Rewrite_no_label', 'paws_labeled_final_context_question', 'paws_labeled_final_context_question_no_label', 'paws_labeled_final_paraphrase_task', 'paws_labeled_final_task_description_no_label', 'piqa_Correct_the_solution', 'piqa_Correct_the_solution_if_false_from_sol_1', 'piqa_Correct_the_solution_if_false_from_sol_2', 'piqa_Does_this_solution_make_sense_sol1', 'piqa_Does_this_solution_make_sense_sol2', 'piqa_choose_the_most_appropriate_solution', 'piqa_finish_sentence_with_correct_choice', 'piqa_no_prompt_needed', 'piqa_pick_correct_choice_index', 'piqa_pick_correct_choice_with_choice_given_before_goal', 'piqa_what_is_the_correct_ending', 'qasc_is_correct_1', 'qasc_is_correct_2', 'qasc_qa_with_combined_facts_1', 'qasc_qa_with_separated_facts_1', 'qasc_qa_with_separated_facts_2', 'qasc_qa_with_separated_facts_3', 'qasc_qa_with_separated_facts_4', 'qasc_qa_with_separated_facts_5', 'quail_context_description_question_answer_id', 'quail_context_description_question_answer_text', 'quail_context_description_question_text', 'quail_context_question_answer_description_id', 'quail_context_question_answer_description_text', 'quail_context_question_description_answer_id', 'quail_context_question_description_answer_text', 'quail_context_question_description_text', 'quail_description_context_question_answer_id', 'quail_description_context_question_answer_text', 'quail_description_context_question_text', 'quail_no_prompt_id', 'quail_no_prompt_text', 'quarel_choose_between', 'quarel_do_not_use', 'quarel_heres_a_story', 'quarel_logic_test', 'quarel_testing_students', 'quartz_answer_question_based_on', 'quartz_answer_question_below', 'quartz_given_the_fact_answer_the_q', 'quartz_having_read_above_passage', 'quartz_paragraph_question_plain_concat', 'quartz_read_passage_below_choose', 'quartz_use_info_from_paragraph_question', 'quartz_use_info_from_question_paragraph', 'quoref_Answer_Friend_Question', 'quoref_Answer_Question_Given_Context', 'quoref_Answer_Test', 'quoref_Context_Contains_Answer', 'quoref_Find_Answer', 'quoref_Found_Context_Online', 'quoref_Given_Context_Answer_Question', 'quoref_Guess_Answer', 'quoref_Guess_Title_For_Context', 'quoref_Read_And_Extract_', 'quoref_What_Is_The_Answer', 'race_high_Is_this_the_right_answer', 'race_high_Read_the_article_and_answer_the_question_no_option_', 'race_high_Select_the_best_answer', 'race_high_Select_the_best_answer_generate_span_', 'race_high_Select_the_best_answer_no_instructions_', 'race_high_Taking_a_test', 'race_high_Write_a_multi_choice_question_for_the_following_article', 'race_high_Write_a_multi_choice_question_options_given_', 'race_middle_Is_this_the_right_answer', 'race_middle_Read_the_article_and_answer_the_question_no_option_', 'race_middle_Select_the_best_answer', 'race_middle_Select_the_best_answer_generate_span_', 'race_middle_Select_the_best_answer_no_instructions_', 'race_middle_Taking_a_test', 'race_middle_Write_a_multi_choice_question_for_the_following_article', 'race_middle_Write_a_multi_choice_question_options_given_', 'ropes_background_new_situation_answer', 'ropes_background_situation_middle', 'ropes_given_background_situation', 'ropes_new_situation_background_answer', 'ropes_plain_background_situation', 'ropes_plain_bottom_hint', 'ropes_plain_no_background', 'ropes_prompt_beginning', 'ropes_prompt_bottom_hint_beginning', 'ropes_prompt_bottom_no_hint', 'ropes_prompt_mix', 'ropes_read_background_situation', 'rotten_tomatoes_Movie_Expressed_Sentiment', 'rotten_tomatoes_Movie_Expressed_Sentiment_2', 'rotten_tomatoes_Reviewer_Enjoyment', 'rotten_tomatoes_Reviewer_Enjoyment_Yes_No', 'rotten_tomatoes_Reviewer_Expressed_Sentiment', 'rotten_tomatoes_Reviewer_Opinion_bad_good_choices', 'rotten_tomatoes_Reviewer_Sentiment_Feeling', 'rotten_tomatoes_Sentiment_with_choices_', 'rotten_tomatoes_Text_Expressed_Sentiment', 'rotten_tomatoes_Writer_Expressed_Sentiment', 'samsum_Generate_a_summary_for_this_dialogue', 'samsum_Given_the_above_dialogue_write_a_summary', 'samsum_Sum_up_the_following_dialogue', 'samsum_Summarize_', 'samsum_Summarize_this_dialogue_', 'samsum_To_sum_up_this_dialog', 'samsum_Write_a_dialogue_that_match_this_summary', 'sciq_Direct_Question', 'sciq_Direct_Question_Closed_Book_', 'sciq_Multiple_Choice', 'sciq_Multiple_Choice_Closed_Book_', 'sciq_Multiple_Choice_Question_First', 'social_i_qa_Check_if_a_random_answer_is_valid_or_not', 'social_i_qa_Generate_answer', 'social_i_qa_Generate_the_question_from_the_answer', 'social_i_qa_I_was_wondering', 'social_i_qa_Show_choices_and_generate_answer', 'social_i_qa_Show_choices_and_generate_index', 'squad_v2_Jeopardy_with_Context', 'squad_v2_Jeopardy_without_Context', 'squad_v2_Questions_with_Context', 'squad_v2_Questions_with_Context_Without_Prompt_Keywords', 'squad_v2_Questions_with_Context_Without_Prompt_Keywords_unanswerable', 'squad_v2_Questions_with_Context_unanswerable', 'squad_v2_Topic_Prediction_Context', 'squad_v2_Topic_Prediction_Context_with_randomized_prompt_options', 'squad_v2_Topic_Prediction_Context_with_randomized_prompt_options_placed_in_the_end', 'squad_v2_Topic_Prediction_Question_and_Answer_Pair', 'squad_v2_Trivia', 'squad_v2_Unanwerable_question', 'super_glue_boolq_GPT_3_Style', 'super_glue_boolq_I_wonder_', 'super_glue_boolq_after_reading', 'super_glue_boolq_based_on_the_following_passage', 'super_glue_boolq_based_on_the_previous_passage', 'super_glue_boolq_could_you_tell_me_', 'super_glue_boolq_exam', 'super_glue_boolq_exercise', 'super_glue_boolq_valid_binary', 'super_glue_boolq_yes_no_question', 'super_glue_cb_GPT_3_style', 'super_glue_cb_GPT_3_style_score_eval', 'super_glue_cb_MNLI_crowdsource', 'super_glue_cb_MNLI_crowdsource_score_eval', 'super_glue_cb_always_sometimes_never', 'super_glue_cb_always_sometimes_never_score_eval', 'super_glue_cb_based_on_the_previous_passage', 'super_glue_cb_based_on_the_previous_passage_score_eval', 'super_glue_cb_can_we_infer', 'super_glue_cb_can_we_infer_score_eval', 'super_glue_cb_claim_true_false_inconclusive', 'super_glue_cb_claim_true_false_inconclusive_score_eval', 'super_glue_cb_consider_always_sometimes_never', 'super_glue_cb_consider_always_sometimes_never_score_eval', 'super_glue_cb_does_it_follow_that', 'super_glue_cb_does_it_follow_that_score_eval', 'super_glue_cb_does_this_imply', 'super_glue_cb_does_this_imply_score_eval', 'super_glue_cb_guaranteed_possible_impossible', 'super_glue_cb_guaranteed_possible_impossible_score_eval', 'super_glue_cb_guaranteed_true', 'super_glue_cb_guaranteed_true_score_eval', 'super_glue_cb_justified_in_saying', 'super_glue_cb_justified_in_saying_score_eval', 'super_glue_cb_must_be_true', 'super_glue_cb_must_be_true_score_eval', 'super_glue_cb_should_assume', 'super_glue_cb_should_assume_score_eval', 'super_glue_cb_take_the_following_as_truth', 'super_glue_cb_take_the_following_as_truth_score_eval', 'super_glue_copa_C1_or_C2_premise_so_because_', 'super_glue_copa_C1_or_C2_premise_so_because__score_eval', 'super_glue_copa__As_a_result_C1_or_C2_', 'super_glue_copa__As_a_result_C1_or_C2__score_eval', 'super_glue_copa__What_could_happen_next_C1_or_C2_', 'super_glue_copa__What_could_happen_next_C1_or_C2__score_eval', 'super_glue_copa__which_may_be_caused_by', 'super_glue_copa__which_may_be_caused_by_score_eval', 'super_glue_copa__why_C1_or_C2', 'super_glue_copa__why_C1_or_C2_score_eval', 'super_glue_copa_best_option', 'super_glue_copa_best_option_score_eval', 'super_glue_copa_cause_effect', 'super_glue_copa_cause_effect_score_eval', 'super_glue_copa_choose', 'super_glue_copa_choose_score_eval', 'super_glue_copa_exercise', 'super_glue_copa_exercise_score_eval', 'super_glue_copa_i_am_hesitating', 'super_glue_copa_i_am_hesitating_score_eval', 'super_glue_copa_more_likely', 'super_glue_copa_more_likely_score_eval', 'super_glue_copa_plausible_alternatives', 'super_glue_copa_plausible_alternatives_score_eval', 'super_glue_multirc_I_was_going_to_say_', 'super_glue_multirc_Would_it_be_good_to_answer_', 'super_glue_multirc_confirm', 'super_glue_multirc_correct', 'super_glue_multirc_decide_valid', 'super_glue_multirc_found_this_answer', 'super_glue_multirc_grading', 'super_glue_multirc_is_a_correct_answer_', 'super_glue_multirc_is_the_correct_answer_', 'super_glue_multirc_paragraph_question_is_it_', 'super_glue_record_Add_sentence_after_after_continuation_choices_', 'super_glue_record_Add_sentence_after_continuation_choices_', 'super_glue_record_Can_you_figure_out_', 'super_glue_record_GPT_3_style_continuation_choices_', 'super_glue_record_GPT_3_style_summary_only_continuation_choices_', 'super_glue_record_GPT_3_style_with_labels_continuation_choices_', 'super_glue_record_GPT_3_style_with_labels_without_hyphens_continuation_choices_', 'super_glue_record_GPT_3_style_without_hyphens_continuation_choices_', 'super_glue_record_In_the_question_above_the_placeholder_stands_for', 'super_glue_record_New_highlight_continuation_choices_', 'super_glue_record_News_article_continuation_choices_', 'super_glue_record_Summary_first_continuation_choices_', 'super_glue_record_What_could_the_placeholder_be_', 'super_glue_record_Which_one_is_the_placeholder_', 'super_glue_record_choose_between', 'super_glue_record_corrupted', 'super_glue_record_exercise', 'super_glue_record_pick_one_option', 'super_glue_record_the_placeholder_refers_to_', 'super_glue_record_trying_to_decide', 'super_glue_rte_GPT_3_style', 'super_glue_rte_GPT_3_style_score_eval', 'super_glue_rte_MNLI_crowdsource', 'super_glue_rte_MNLI_crowdsource_score_eval', 'super_glue_rte_based_on_the_previous_passage', 'super_glue_rte_based_on_the_previous_passage_score_eval', 'super_glue_rte_can_we_infer', 'super_glue_rte_can_we_infer_score_eval', 'super_glue_rte_does_it_follow_that', 'super_glue_rte_does_it_follow_that_score_eval', 'super_glue_rte_does_this_imply', 'super_glue_rte_does_this_imply_score_eval', 'super_glue_rte_guaranteed_true', 'super_glue_rte_guaranteed_true_score_eval', 'super_glue_rte_justified_in_saying', 'super_glue_rte_justified_in_saying_score_eval', 'super_glue_rte_must_be_true', 'super_glue_rte_must_be_true_score_eval', 'super_glue_rte_should_assume', 'super_glue_rte_should_assume_score_eval', 'super_glue_wic_GPT_3_prompt', 'super_glue_wic_GPT_3_prompt_score_eval', 'super_glue_wic_GPT_3_prompt_with_label', 'super_glue_wic_GPT_3_prompt_with_label_score_eval', 'super_glue_wic_affirmation_true_or_false', 'super_glue_wic_affirmation_true_or_false_score_eval', 'super_glue_wic_grammar_homework', 'super_glue_wic_grammar_homework_score_eval', 'super_glue_wic_polysemous', 'super_glue_wic_polysemous_score_eval', 'super_glue_wic_question_context', 'super_glue_wic_question_context_meaning', 'super_glue_wic_question_context_meaning_score_eval', 'super_glue_wic_question_context_meaning_with_label', 'super_glue_wic_question_context_meaning_with_label_score_eval', 'super_glue_wic_question_context_score_eval', 'super_glue_wic_same_sense', 'super_glue_wic_same_sense_score_eval', 'super_glue_wic_similar_sense', 'super_glue_wic_similar_sense_score_eval', 'super_glue_wsc.fixed_GPT_3_Style', 'super_glue_wsc.fixed_GPT_3_Style_score_eval', 'super_glue_wsc.fixed_I_think_they_mean', 'super_glue_wsc.fixed_I_think_they_mean_score_eval', 'super_glue_wsc.fixed_Who_or_what_is_are', 'super_glue_wsc.fixed_Who_or_what_is_are_score_eval', 'super_glue_wsc.fixed_by_p_they_mean', 'super_glue_wsc.fixed_by_p_they_mean_score_eval', 'super_glue_wsc.fixed_does_p_stand_for', 'super_glue_wsc.fixed_does_p_stand_for_score_eval', 'super_glue_wsc.fixed_does_the_pronoun_refer_to', 'super_glue_wsc.fixed_does_the_pronoun_refer_to_score_eval', 'super_glue_wsc.fixed_in_other_words', 'super_glue_wsc.fixed_in_other_words_score_eval', 'super_glue_wsc.fixed_p_is_are_r', 'super_glue_wsc.fixed_p_is_are_r_score_eval', 'super_glue_wsc.fixed_replaced_with', 'super_glue_wsc.fixed_replaced_with_score_eval', 'super_glue_wsc.fixed_the_pronoun_refers_to', 'super_glue_wsc.fixed_the_pronoun_refers_to_score_eval', 'trec_fine_grained_ABBR', 'trec_fine_grained_ABBR_context_first', 'trec_fine_grained_DESC', 'trec_fine_grained_DESC_context_first', 'trec_fine_grained_ENTY', 'trec_fine_grained_HUM', 'trec_fine_grained_HUM_context_first', 'trec_fine_grained_LOC', 'trec_fine_grained_LOC_context_first', 'trec_fine_grained_NUM', 'trec_fine_grained_NUM_context_first', 'trec_fine_grained_open', 'trec_fine_grained_open_context_first', 'trec_pick_the_best_descriptor', 'trec_trec1', 'trec_trec2', 'trec_what_category_best_describe', 'trec_which_category_best_describes', 'trivia_qa_unfiltered_first_person_context', 'trivia_qa_unfiltered_formal_description', 'trivia_qa_unfiltered_guess_question', 'trivia_qa_unfiltered_question_answer', 'trivia_qa_unfiltered_question_with_instruction', 'web_questions_get_the_answer', 'web_questions_potential_correct_answer', 'web_questions_question_answer', 'web_questions_short_general_knowledge_q', 'web_questions_whats_the_answer', 'wiki_bio_comprehension', 'wiki_bio_guess_person', 'wiki_bio_key_content', 'wiki_bio_what_content', 'wiki_bio_who', 'wiki_hop_original_choose_best_object_affirmative_1', 'wiki_hop_original_choose_best_object_affirmative_2', 'wiki_hop_original_choose_best_object_affirmative_3', 'wiki_hop_original_choose_best_object_interrogative_1', 'wiki_hop_original_choose_best_object_interrogative_2', 'wiki_hop_original_explain_relation', 'wiki_hop_original_generate_object', 'wiki_hop_original_generate_subject', 'wiki_hop_original_generate_subject_and_object', 'wiki_qa_Decide_good_answer', 'wiki_qa_Direct_Answer_to_Question', 'wiki_qa_Generate_Question_from_Topic', 'wiki_qa_Is_This_True_', 'wiki_qa_Jeopardy_style', 'wiki_qa_Topic_Prediction_Answer_Only', 'wiki_qa_Topic_Prediction_Question_Only', 'wiki_qa_Topic_Prediction_Question_and_Answer_Pair', 'wiki_qa_automatic_system', 'wiki_qa_exercise', 'wiki_qa_found_on_google', 'winogrande_winogrande_debiased_Replace', 'winogrande_winogrande_debiased_Replace_score_eval', 'winogrande_winogrande_debiased_does_underscore_refer_to', 'winogrande_winogrande_debiased_does_underscore_refer_to_score_eval', 'winogrande_winogrande_debiased_fill_in_the_blank', 'winogrande_winogrande_debiased_fill_in_the_blank_score_eval', 'winogrande_winogrande_debiased_stand_for', 'winogrande_winogrande_debiased_stand_for_score_eval', 'winogrande_winogrande_debiased_underscore_refer_to', 'winogrande_winogrande_debiased_underscore_refer_to_score_eval', 'winogrande_winogrande_xl_Replace', 'winogrande_winogrande_xl_Replace_score_eval', 'winogrande_winogrande_xl_does_underscore_refer_to', 'winogrande_winogrande_xl_does_underscore_refer_to_score_eval', 'winogrande_winogrande_xl_fill_in_the_blank', 'winogrande_winogrande_xl_fill_in_the_blank_score_eval', 'winogrande_winogrande_xl_stand_for', 'winogrande_winogrande_xl_stand_for_score_eval', 'winogrande_winogrande_xl_underscore_refer_to', 'winogrande_winogrande_xl_underscore_refer_to_score_eval', 'wiqa_does_the_supposed_perturbation_have_an_effect', 'wiqa_effect_with_label_answer', 'wiqa_effect_with_string_answer', 'wiqa_what_is_the_final_step_of_the_following_process', 'wiqa_what_is_the_missing_first_step', 'wiqa_what_might_be_the_first_step_of_the_process', 'wiqa_what_might_be_the_last_step_of_the_process', 'wiqa_which_of_the_following_is_the_supposed_perturbation', 'xsum_DOC_boils_down_to_simple_idea_that', 'xsum_DOC_given_above_write_one_sentence', 'xsum_DOC_how_would_you_rephrase_few_words', 'xsum_DOC_tldr', 'xsum_DOC_write_summary_of_above', 'xsum_article_DOC_summary', 'xsum_college_roommate_asked_DOC_so_I_recap', 'xsum_read_below_DOC_write_abstract', 'xsum_summarize_DOC', 'xsum_summarize_this_DOC_summary', 'yelp_review_full_based_on_that', 'yelp_review_full_format_rating', 'yelp_review_full_format_score', 'yelp_review_full_format_star', 'yelp_review_full_on_a_scale', 'yelp_review_full_so_i_would', 'yelp_review_full_this_place']\n",
    "\n",
    "all_datasets = [('glue', 'mrpc', 'validation'), ('glue', 'qqp', 'validation'), ('paws', 'labeled_final', 'validation'), ('ai2_arc', 'ARC-Challenge', 'validation'), ('ai2_arc', 'ARC-Easy', 'validation'), ('kilt_tasks', 'hotpotqa', 'validation'), ('trivia_qa', 'unfiltered', 'validation'), ('web_questions', None, 'test'), ('wiki_qa', None, 'validation'), ('adversarial_qa', 'dbidaf', 'validation'), ('adversarial_qa', 'dbert', 'validation'), ('adversarial_qa', 'droberta', 'validation'), ('duorc', 'SelfRC', 'validation'), ('duorc', 'ParaphraseRC', 'validation'), ('ropes', None, 'validation'), ('squad_v2', None, 'validation'), ('super_glue', 'record', 'validation'), ('quoref', None, 'validation'), ('tydiqa', 'primary_task', 'validation'), ('cos_e', 'v1.11', 'validation'), ('cosmos_qa', None, 'validation'), ('dream', None, 'validation'), ('openbookqa', 'main', 'validation'), ('qasc', None, 'validation'), ('quail', None, 'validation'), ('quarel', None, 'validation'), ('quartz', None, 'validation'), ('race', 'high', 'validation'), ('race', 'middle', 'validation'), ('sciq', None, 'validation'), ('social_i_qa', None, 'validation'), ('super_glue', 'boolq', 'validation'), ('super_glue', 'multirc', 'validation'), ('wiki_hop', 'original', 'validation'), ('wiqa', None, 'validation'), ('piqa', None, 'validation'), ('amazon_polarity', None, 'test'), ('app_reviews', None, 'train'), ('imdb', None, 'test'), ('rotten_tomatoes', None, 'validation'), ('yelp_review_full', None, 'test'), ('common_gen', None, 'validation'), ('wiki_bio', None, 'val'), ('cnn_dailymail', '3.0.0', 'validation'), ('gigaword', None, 'validation'), ('multi_news', None, 'validation'), ('xsum', None, 'validation'), ('samsum', None, 'validation'), ('ag_news', None, 'test'), ('dbpedia_14', None, 'test'), ('trec', None, 'test')]\n",
    "\n",
    "# for p3_dataset in configs:\n",
    "#     data = datasets.load_dataset('bigscience/P3', p3_dataset, cache_dir=cache_dir)\n",
    "\n",
    "for dataset_name, subset, split in all_datasets:\n",
    "    print(dataset_name, subset, split)\n",
    "    dataset = datasets.load_dataset(dataset_name, subset, split=split)\n",
    "\n",
    "    prompts = DatasetTemplates(dataset, subset)\n",
    "    prompt_names = prompts.all_template_names\n",
    "    original_prompts =[n for n in prompt_names if prompts[n].metadata.original_task]\n",
    "    non_original_prompts = [n for n in prompt_names if not prompts[n].metadata.original_task]\n",
    "\n",
    "    for pname in prompt_names:\n",
    "        p3_dataset = f'{dataset_name}_{subset}_{pname}' if subset else f'{dataset_name}_{pname}'\n",
    "        p3_dataset = datasets.load_dataset('bigscience/P3', p3_dataset, cache_dir=cache_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('t0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0183d35da8c3acba781927c3c59608af6a5fa19ba2ce09ea8ba21915e4804f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
